{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c9dbb26",
   "metadata": {},
   "source": [
    "## Métodos de Classificação e Comparação\n",
    "\n",
    "### Começando com TF-IDF + modelos lineares\n",
    "\n",
    "**TF-IDF (Term Frequency–Inverse Document Frequency)** é uma forma simples e muito eficaz de transformar texto em números.\n",
    "A ideia é dar **peso alto** para termos que aparecem com frequência em um ticket (**TF**) e são relativamente **raros no corpus** (**IDF**).\n",
    "\n",
    "Na prática, usamos TF-IDF com **n-grams** de:\n",
    "- **palavras** (captura expressões como \"password reset\"), e\n",
    "- **caracteres** (ajuda com abreviações, variações e erros de digitação, comuns em tickets).\n",
    "\n",
    "Isso gera um **vetor esparso de alta dimensão** por ticket. Em seguida, um **classificador linear** aprende um peso para cada feature (n-gram) e decide a classe pela soma ponderada desses pesos.\n",
    "\n",
    "Por que faz sentido aqui (conforme a análise exploratória):\n",
    "- **Textos curtos e vocabulário característico** → n-grams capturam bem padrões locais.\n",
    "- **Dataset grande e desbalanceado** → modelos lineares são fortes e eficientes;\n",
    "\n",
    "Vamos testar três variantes lineares com TF-IDF e comparar principalmente pelo **F1 macro**.\n",
    "\n",
    "### Protocolo de avaliação\n",
    "\n",
    "- Treinamos nos dados de **treino** e avaliamos no **teste**.\n",
    "- Métrica principal: **F1 macro**, para equilibrar o desempenho entre classes.\n",
    "- Também reportamos **accuracy** e **F1 weighted** para referência.\n",
    "- O conjunto de **validação** fica reservado para a avaliação final (quando a solução já estiver definida).\n",
    "- Mantemos a reprodutibilidade usando `RANDOM_STATE` em splits e modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f75056b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divisão dos dados para os testes dos classificadores:\n",
      "  Treino:      38,109 tickets\n",
      "  Teste:       9,528 tickets\n",
      "  Validação:   200 tickets\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from classifier.classifiers import (\n",
    "    EmbeddingClassifier,\n",
    "    RagKnnClassifier,\n",
    "    RagWeightedVoteClassifier,\n",
    "    TfidfClassifier,\n",
    ")\n",
    "from classifier.config import RANDOM_STATE, VALIDATION_SIZE\n",
    "from classifier.data import load_dataset, train_test_validation_split\n",
    "from classifier.metrics import evaluate\n",
    "\n",
    "# Verbosidade do scikit-learn (1+ imprime progresso do solver quando suportado)\n",
    "SKLEARN_VERBOSE = 1\n",
    "\n",
    "# Carregar e dividir o dataset para os testes dos classificadores\n",
    "df, classes = load_dataset()\n",
    "train_df, test_df, validation_df = train_test_validation_split(\n",
    "    df,\n",
    "    validation_size=VALIDATION_SIZE,\n",
    "    train_size=0.8,\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "print(\"Divisão dos dados para os testes dos classificadores:\")\n",
    "print(f\"  Treino:      {len(train_df):,} tickets\")\n",
    "print(f\"  Teste:       {len(test_df):,} tickets\")\n",
    "print(f\"  Validação:   {len(validation_df):,} tickets\")\n",
    "\n",
    "test_texts = test_df[\"Document\"].tolist()\n",
    "test_labels = test_df[\"Topic_group\"].tolist()\n",
    "\n",
    "def evaluate_classifier(classifier):\n",
    "    print(f\"\\n==> {classifier.name}\")\n",
    "    print(\"==> Treinando...\")\n",
    "    classifier.fit(train_df)\n",
    "    print(\"==> Treinando... OK\")\n",
    "\n",
    "    print(f\"==> Classificando no teste: {len(test_texts):,} tickets\")\n",
    "    if isinstance(classifier, (RagKnnClassifier, RagWeightedVoteClassifier)):\n",
    "        y_pred = classifier.predict(tqdm(test_texts, desc=\"Predizendo\", total=len(test_texts)))\n",
    "    else:\n",
    "        y_pred = classifier.predict(test_texts)\n",
    "    metrics = evaluate(test_labels, y_pred, classes)\n",
    "    return metrics, y_pred\n",
    "\n",
    "def print_metrics(metrics, name=None):\n",
    "    title = f\"Métricas ({name})\" if name else \"Métricas\"\n",
    "    print(title)\n",
    "    print(f\"  accuracy:    {metrics['accuracy']:.4f}\")\n",
    "    print(f\"  f1_macro:    {metrics['f1_macro']:.4f}\")\n",
    "    print(f\"  f1_weighted: {metrics['f1_weighted']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe2a9bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "random.seed(RANDOM_STATE)\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "\n",
    "    torch.manual_seed(RANDOM_STATE)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(RANDOM_STATE)\n",
    "except ImportError:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64422ae",
   "metadata": {},
   "source": [
    "### TF-IDF + LinearSVC\n",
    "\n",
    "O **LinearSVC** é uma SVM linear e costuma ser uma baseline muito forte para **texto em TF-IDF**, porque lida bem com vetores esparsos e de alta dimensão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fd49b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> TF-IDF + LinearSVC\n",
      "==> Treinando...\n",
      "[LibLinear].....**\n",
      "optimization finished, #iter = 57\n",
      "Objective value = -1525.100119\n",
      "nSV = 7356\n",
      "............**.\n",
      "optimization finished, #iter = 130\n",
      "Objective value = -840.010881\n",
      "nSV = 3608\n",
      ".....*\n",
      "optimization finished, #iter = 57\n",
      "Objective value = -2671.115288\n",
      "nSV = 11603\n",
      ".....*\n",
      "optimization finished, #iter = 59\n",
      "Objective value = -3452.154035\n",
      "nSV = 15053\n",
      ".........**\n",
      "optimization finished, #iter = 98\n",
      "Objective value = -685.837045\n",
      "nSV = 3195\n",
      "......**\n",
      "optimization finished, #iter = 63\n",
      "Objective value = -2261.285826\n",
      "nSV = 9071\n",
      ".........**\n",
      "optimization finished, #iter = 99\n",
      "Objective value = -396.591229\n",
      "nSV = 2392\n",
      "...........**\n",
      "optimization finished, #iter = 119\n",
      "Objective value = -711.213314\n",
      "nSV = 3156\n",
      "==> Treinando... OK\n",
      "==> Classificando no teste: 9,528 tickets\n",
      "Métricas (TF-IDF + LinearSVC)\n",
      "  accuracy:    0.8637\n",
      "  f1_macro:    0.8641\n",
      "  f1_weighted: 0.8639\n"
     ]
    }
   ],
   "source": [
    "tfidf_linear = TfidfClassifier.linear_svc(\n",
    "    random_state=RANDOM_STATE, verbose=SKLEARN_VERBOSE\n",
    ")\n",
    "tfidf_linear_metrics, tfidf_linear_pred = evaluate_classifier(tfidf_linear)\n",
    "print_metrics(tfidf_linear_metrics, tfidf_linear.name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0aab610",
   "metadata": {},
   "source": [
    "### TF-IDF + Logistic Regression\n",
    "\n",
    "**Logistic Regression** (multiclasse) é um modelo linear que aprende pesos por feature, mas produz **probabilidades** (via softmax). Em texto com TF-IDF, costuma ser competitiva e ajuda quando queremos interpretar confiança.\n",
    "\n",
    "Aqui, usamos `class_weight` para mitigar desbalanceamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae429401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> TF-IDF + LogisticRegression\n",
      "==> Treinando...\n",
      "Epoch 1, change: 1\n",
      "Epoch 2, change: 0.21204642\n",
      "Epoch 3, change: 0.15717247\n",
      "Epoch 4, change: 0.11930938\n",
      "Epoch 5, change: 0.19036197\n",
      "Epoch 6, change: 0.12147558\n",
      "Epoch 7, change: 0.12233366\n",
      "Epoch 8, change: 0.12060319\n",
      "Epoch 9, change: 0.084166522\n",
      "Epoch 10, change: 0.07419601\n",
      "Epoch 11, change: 0.087779841\n",
      "Epoch 12, change: 0.10499883\n",
      "Epoch 13, change: 0.1285004\n",
      "Epoch 14, change: 0.0881494\n",
      "Epoch 15, change: 0.10128045\n",
      "Epoch 16, change: 0.098006652\n",
      "Epoch 17, change: 0.13036561\n",
      "Epoch 18, change: 0.13934241\n",
      "Epoch 19, change: 0.11259884\n",
      "Epoch 20, change: 0.075093463\n",
      "Epoch 21, change: 0.098438402\n",
      "Epoch 22, change: 0.14155024\n",
      "Epoch 23, change: 0.10596595\n",
      "Epoch 24, change: 0.11865774\n",
      "Epoch 25, change: 0.089767268\n",
      "Epoch 26, change: 0.15165014\n",
      "Epoch 27, change: 0.081902808\n",
      "Epoch 28, change: 0.12846351\n",
      "Epoch 29, change: 0.086500155\n",
      "Epoch 30, change: 0.12040105\n",
      "Epoch 31, change: 0.084020956\n",
      "Epoch 32, change: 0.094923467\n",
      "Epoch 33, change: 0.082344761\n",
      "Epoch 34, change: 0.11244378\n",
      "Epoch 35, change: 0.11072836\n",
      "Epoch 36, change: 0.096479828\n",
      "Epoch 37, change: 0.079191694\n",
      "Epoch 38, change: 0.11711498\n",
      "Epoch 39, change: 0.12795418\n",
      "Epoch 40, change: 0.075419192\n",
      "Epoch 41, change: 0.081572057\n",
      "Epoch 42, change: 0.15275943\n",
      "Epoch 43, change: 0.087076022\n",
      "Epoch 44, change: 0.10980795\n",
      "Epoch 45, change: 0.073039968\n",
      "Epoch 46, change: 0.065242245\n",
      "Epoch 47, change: 0.070998388\n",
      "Epoch 48, change: 0.083614263\n",
      "Epoch 49, change: 0.12139402\n",
      "Epoch 50, change: 0.068401909\n",
      "Epoch 51, change: 0.086273786\n",
      "Epoch 52, change: 0.092027064\n",
      "Epoch 53, change: 0.080611695\n",
      "Epoch 54, change: 0.10116299\n",
      "Epoch 55, change: 0.11704735\n",
      "Epoch 56, change: 0.10475026\n",
      "Epoch 57, change: 0.12461705\n",
      "Epoch 58, change: 0.12710171\n",
      "Epoch 59, change: 0.096464753\n",
      "Epoch 60, change: 0.1188965\n",
      "Epoch 61, change: 0.12151991\n",
      "Epoch 62, change: 0.13263093\n",
      "Epoch 63, change: 0.13546929\n",
      "Epoch 64, change: 0.14286082\n",
      "Epoch 65, change: 0.073952112\n",
      "Epoch 66, change: 0.11715918\n",
      "Epoch 67, change: 0.10808734\n",
      "Epoch 68, change: 0.078444957\n",
      "Epoch 69, change: 0.11402924\n",
      "Epoch 70, change: 0.10352036\n",
      "Epoch 71, change: 0.10156821\n",
      "Epoch 72, change: 0.14969011\n",
      "Epoch 73, change: 0.10155976\n",
      "Epoch 74, change: 0.10513952\n",
      "Epoch 75, change: 0.11272111\n",
      "Epoch 76, change: 0.10992243\n",
      "Epoch 77, change: 0.11132201\n",
      "Epoch 78, change: 0.090863019\n",
      "Epoch 79, change: 0.10195346\n",
      "Epoch 80, change: 0.11929044\n",
      "Epoch 81, change: 0.1450432\n",
      "Epoch 82, change: 0.083019593\n",
      "Epoch 83, change: 0.1070361\n",
      "Epoch 84, change: 0.10927871\n",
      "Epoch 85, change: 0.092824704\n",
      "Epoch 86, change: 0.12844489\n",
      "Epoch 87, change: 0.10874435\n",
      "Epoch 88, change: 0.077640637\n",
      "Epoch 89, change: 0.079000234\n",
      "Epoch 90, change: 0.065769049\n",
      "Epoch 91, change: 0.098967063\n",
      "Epoch 92, change: 0.12842389\n",
      "Epoch 93, change: 0.098135863\n",
      "Epoch 94, change: 0.094466016\n",
      "Epoch 95, change: 0.071632063\n",
      "Epoch 96, change: 0.066557133\n",
      "Epoch 97, change: 0.093284749\n",
      "Epoch 98, change: 0.096440817\n",
      "Epoch 99, change: 0.074258032\n",
      "Epoch 100, change: 0.11258642\n",
      "Epoch 101, change: 0.096995933\n",
      "Epoch 102, change: 0.079644342\n",
      "Epoch 103, change: 0.092932888\n",
      "Epoch 104, change: 0.080430133\n",
      "Epoch 105, change: 0.08807683\n",
      "Epoch 106, change: 0.10580882\n",
      "Epoch 107, change: 0.12187919\n",
      "Epoch 108, change: 0.14186684\n",
      "Epoch 109, change: 0.1087645\n",
      "Epoch 110, change: 0.069901007\n",
      "Epoch 111, change: 0.069781316\n",
      "Epoch 112, change: 0.13447593\n",
      "Epoch 113, change: 0.1290122\n",
      "Epoch 114, change: 0.082621095\n",
      "Epoch 115, change: 0.13250099\n",
      "Epoch 116, change: 0.095568563\n",
      "Epoch 117, change: 0.12391452\n",
      "Epoch 118, change: 0.1067243\n",
      "Epoch 119, change: 0.12433557\n",
      "Epoch 120, change: 0.075043858\n",
      "Epoch 121, change: 0.081974995\n",
      "Epoch 122, change: 0.11033931\n",
      "Epoch 123, change: 0.10065801\n",
      "Epoch 124, change: 0.11820122\n",
      "Epoch 125, change: 0.1150201\n",
      "Epoch 126, change: 0.076471726\n",
      "Epoch 127, change: 0.074188705\n",
      "Epoch 128, change: 0.13503898\n",
      "Epoch 129, change: 0.080551408\n",
      "Epoch 130, change: 0.090686608\n",
      "Epoch 131, change: 0.13649543\n",
      "Epoch 132, change: 0.12784561\n",
      "Epoch 133, change: 0.12381003\n",
      "Epoch 134, change: 0.073532487\n",
      "Epoch 135, change: 0.095887081\n",
      "Epoch 136, change: 0.07202816\n",
      "Epoch 137, change: 0.11512677\n",
      "Epoch 138, change: 0.092226522\n",
      "Epoch 139, change: 0.1367755\n",
      "Epoch 140, change: 0.11391878\n",
      "Epoch 141, change: 0.12180576\n",
      "Epoch 142, change: 0.12022108\n",
      "Epoch 143, change: 0.071692909\n",
      "Epoch 144, change: 0.073875077\n",
      "Epoch 145, change: 0.093466836\n",
      "Epoch 146, change: 0.13456592\n",
      "Epoch 147, change: 0.10341256\n",
      "Epoch 148, change: 0.1249745\n",
      "Epoch 149, change: 0.10450083\n",
      "Epoch 150, change: 0.11357734\n",
      "Epoch 151, change: 0.10622695\n",
      "Epoch 152, change: 0.10657238\n",
      "Epoch 153, change: 0.105247\n",
      "Epoch 154, change: 0.14039838\n",
      "Epoch 155, change: 0.12501785\n",
      "Epoch 156, change: 0.12423915\n",
      "Epoch 157, change: 0.092184867\n",
      "Epoch 158, change: 0.11255562\n",
      "Epoch 159, change: 0.069197058\n",
      "Epoch 160, change: 0.11751475\n",
      "Epoch 161, change: 0.11329118\n",
      "Epoch 162, change: 0.10318986\n",
      "Epoch 163, change: 0.11224919\n",
      "Epoch 164, change: 0.13872447\n",
      "Epoch 165, change: 0.080356527\n",
      "Epoch 166, change: 0.13630607\n",
      "Epoch 167, change: 0.083853371\n",
      "Epoch 168, change: 0.12528251\n",
      "Epoch 169, change: 0.12270219\n",
      "Epoch 170, change: 0.082722331\n",
      "Epoch 171, change: 0.14488266\n",
      "Epoch 172, change: 0.078997\n",
      "Epoch 173, change: 0.10928273\n",
      "Epoch 174, change: 0.086235343\n",
      "Epoch 175, change: 0.11728117\n",
      "Epoch 176, change: 0.08192043\n",
      "Epoch 177, change: 0.12036887\n",
      "Epoch 178, change: 0.086282873\n",
      "Epoch 179, change: 0.13273777\n",
      "Epoch 180, change: 0.11138016\n",
      "Epoch 181, change: 0.087721091\n",
      "Epoch 182, change: 0.13007803\n",
      "Epoch 183, change: 0.11186037\n",
      "Epoch 184, change: 0.14418081\n",
      "Epoch 185, change: 0.096934686\n",
      "Epoch 186, change: 0.080348928\n",
      "Epoch 187, change: 0.093053158\n",
      "Epoch 188, change: 0.090394054\n",
      "Epoch 189, change: 0.10585727\n",
      "Epoch 190, change: 0.10582177\n",
      "Epoch 191, change: 0.097843011\n",
      "Epoch 192, change: 0.085406329\n",
      "Epoch 193, change: 0.12452898\n",
      "Epoch 194, change: 0.1280775\n",
      "Epoch 195, change: 0.074499399\n",
      "Epoch 196, change: 0.097847417\n",
      "Epoch 197, change: 0.11474356\n",
      "Epoch 198, change: 0.093042747\n",
      "Epoch 199, change: 0.12278533\n",
      "Epoch 200, change: 0.10078564\n",
      "Epoch 201, change: 0.12894763\n",
      "Epoch 202, change: 0.086575223\n",
      "Epoch 203, change: 0.13995032\n",
      "Epoch 204, change: 0.12825467\n",
      "Epoch 205, change: 0.12438033\n",
      "Epoch 206, change: 0.1201321\n",
      "Epoch 207, change: 0.1134692\n",
      "Epoch 208, change: 0.085534639\n",
      "Epoch 209, change: 0.081842151\n",
      "Epoch 210, change: 0.12862828\n",
      "Epoch 211, change: 0.12414953\n",
      "Epoch 212, change: 0.13042062\n",
      "Epoch 213, change: 0.132974\n",
      "Epoch 214, change: 0.081483248\n",
      "Epoch 215, change: 0.12938542\n",
      "Epoch 216, change: 0.10886206\n",
      "Epoch 217, change: 0.079744146\n",
      "Epoch 218, change: 0.085608036\n",
      "Epoch 219, change: 0.1358462\n",
      "Epoch 220, change: 0.11637357\n",
      "Epoch 221, change: 0.1246339\n",
      "Epoch 222, change: 0.12056515\n",
      "Epoch 223, change: 0.12493672\n",
      "Epoch 224, change: 0.090673267\n",
      "Epoch 225, change: 0.10803881\n",
      "Epoch 226, change: 0.1083135\n",
      "Epoch 227, change: 0.088801629\n",
      "Epoch 228, change: 0.13271556\n",
      "Epoch 229, change: 0.11696622\n",
      "Epoch 230, change: 0.10003479\n",
      "Epoch 231, change: 0.076741249\n",
      "Epoch 232, change: 0.1063766\n",
      "Epoch 233, change: 0.089030821\n",
      "Epoch 234, change: 0.09097918\n",
      "Epoch 235, change: 0.10778012\n",
      "Epoch 236, change: 0.078160218\n",
      "Epoch 237, change: 0.14179328\n",
      "Epoch 238, change: 0.089387311\n",
      "Epoch 239, change: 0.13173553\n",
      "Epoch 240, change: 0.087739559\n",
      "Epoch 241, change: 0.07707763\n",
      "Epoch 242, change: 0.070092208\n",
      "Epoch 243, change: 0.09456859\n",
      "Epoch 244, change: 0.094584694\n",
      "Epoch 245, change: 0.10943494\n",
      "Epoch 246, change: 0.11636176\n",
      "Epoch 247, change: 0.093874686\n",
      "Epoch 248, change: 0.07453864\n",
      "Epoch 249, change: 0.087578023\n",
      "Epoch 250, change: 0.11327765\n",
      "Epoch 251, change: 0.081965422\n",
      "Epoch 252, change: 0.084430459\n",
      "Epoch 253, change: 0.11436437\n",
      "Epoch 254, change: 0.13512674\n",
      "Epoch 255, change: 0.075716225\n",
      "Epoch 256, change: 0.093876075\n",
      "Epoch 257, change: 0.097588867\n",
      "Epoch 258, change: 0.066513361\n",
      "Epoch 259, change: 0.081371024\n",
      "Epoch 260, change: 0.1288351\n",
      "Epoch 261, change: 0.082108102\n",
      "Epoch 262, change: 0.097558165\n",
      "Epoch 263, change: 0.1288222\n",
      "Epoch 264, change: 0.10177454\n",
      "Epoch 265, change: 0.13393983\n",
      "Epoch 266, change: 0.10051798\n",
      "Epoch 267, change: 0.086480178\n",
      "Epoch 268, change: 0.085217045\n",
      "Epoch 269, change: 0.12394965\n",
      "Epoch 270, change: 0.064293136\n",
      "Epoch 271, change: 0.14632768\n",
      "Epoch 272, change: 0.069662062\n",
      "Epoch 273, change: 0.14082564\n",
      "Epoch 274, change: 0.097788906\n",
      "Epoch 275, change: 0.081714706\n",
      "Epoch 276, change: 0.12041625\n",
      "Epoch 277, change: 0.1306025\n",
      "Epoch 278, change: 0.098794021\n",
      "Epoch 279, change: 0.068030664\n",
      "Epoch 280, change: 0.081512158\n",
      "Epoch 281, change: 0.098163339\n",
      "Epoch 282, change: 0.11551638\n",
      "Epoch 283, change: 0.070998874\n",
      "Epoch 284, change: 0.13955414\n",
      "Epoch 285, change: 0.1165632\n",
      "Epoch 286, change: 0.071456383\n",
      "Epoch 287, change: 0.10508723\n",
      "Epoch 288, change: 0.1170215\n",
      "Epoch 289, change: 0.14848703\n",
      "Epoch 290, change: 0.089139535\n",
      "Epoch 291, change: 0.15433476\n",
      "Epoch 292, change: 0.097857013\n",
      "Epoch 293, change: 0.12379578\n",
      "Epoch 294, change: 0.103495\n",
      "Epoch 295, change: 0.09389667\n",
      "Epoch 296, change: 0.10687016\n",
      "Epoch 297, change: 0.10322321\n",
      "Epoch 298, change: 0.092169876\n",
      "Epoch 299, change: 0.093029008\n",
      "Epoch 300, change: 0.10845519\n",
      "Epoch 301, change: 0.12466005\n",
      "Epoch 302, change: 0.10563498\n",
      "Epoch 303, change: 0.068327052\n",
      "Epoch 304, change: 0.079431335\n",
      "Epoch 305, change: 0.10252702\n",
      "Epoch 306, change: 0.12425047\n",
      "Epoch 307, change: 0.1153736\n",
      "Epoch 308, change: 0.14404762\n",
      "Epoch 309, change: 0.11297672\n",
      "Epoch 310, change: 0.11625618\n",
      "Epoch 311, change: 0.10043131\n",
      "Epoch 312, change: 0.099319804\n",
      "Epoch 313, change: 0.076069069\n",
      "Epoch 314, change: 0.13938174\n",
      "Epoch 315, change: 0.14315156\n",
      "Epoch 316, change: 0.095820533\n",
      "Epoch 317, change: 0.13325255\n",
      "Epoch 318, change: 0.11241854\n",
      "Epoch 319, change: 0.11361054\n",
      "Epoch 320, change: 0.10486877\n",
      "Epoch 321, change: 0.14589751\n",
      "Epoch 322, change: 0.11381501\n",
      "Epoch 323, change: 0.069005295\n",
      "Epoch 324, change: 0.13421966\n",
      "Epoch 325, change: 0.14587876\n",
      "Epoch 326, change: 0.067318422\n",
      "Epoch 327, change: 0.14280456\n",
      "Epoch 328, change: 0.12912646\n",
      "Epoch 329, change: 0.10419451\n",
      "Epoch 330, change: 0.10896905\n",
      "Epoch 331, change: 0.11189842\n",
      "Epoch 332, change: 0.12644449\n",
      "Epoch 333, change: 0.08863767\n",
      "Epoch 334, change: 0.13199908\n",
      "Epoch 335, change: 0.13586054\n",
      "Epoch 336, change: 0.087056712\n",
      "Epoch 337, change: 0.08961142\n",
      "Epoch 338, change: 0.09179773\n",
      "Epoch 339, change: 0.14163694\n",
      "Epoch 340, change: 0.10752004\n",
      "Epoch 341, change: 0.10422642\n",
      "Epoch 342, change: 0.058551236\n",
      "Epoch 343, change: 0.13868439\n",
      "Epoch 344, change: 0.10525773\n",
      "Epoch 345, change: 0.082870013\n",
      "Epoch 346, change: 0.069310333\n",
      "Epoch 347, change: 0.093565936\n",
      "Epoch 348, change: 0.096688624\n",
      "Epoch 349, change: 0.12435612\n",
      "Epoch 350, change: 0.12502622\n",
      "Epoch 351, change: 0.075830861\n",
      "Epoch 352, change: 0.13841237\n",
      "Epoch 353, change: 0.094127089\n",
      "Epoch 354, change: 0.099968553\n",
      "Epoch 355, change: 0.14890868\n",
      "Epoch 356, change: 0.11224675\n",
      "Epoch 357, change: 0.11290684\n",
      "Epoch 358, change: 0.082885557\n",
      "Epoch 359, change: 0.10268795\n",
      "Epoch 360, change: 0.11340714\n",
      "Epoch 361, change: 0.092213994\n",
      "Epoch 362, change: 0.10061211\n",
      "Epoch 363, change: 0.096236849\n",
      "Epoch 364, change: 0.13266813\n",
      "Epoch 365, change: 0.083769584\n",
      "Epoch 366, change: 0.13307857\n",
      "Epoch 367, change: 0.084803801\n",
      "Epoch 368, change: 0.11412693\n",
      "Epoch 369, change: 0.1202382\n",
      "Epoch 370, change: 0.085630438\n",
      "Epoch 371, change: 0.077597501\n",
      "Epoch 372, change: 0.11786986\n",
      "Epoch 373, change: 0.087547857\n",
      "Epoch 374, change: 0.077606965\n",
      "Epoch 375, change: 0.14586095\n",
      "Epoch 376, change: 0.12643875\n",
      "Epoch 377, change: 0.10349736\n",
      "Epoch 378, change: 0.143061\n",
      "Epoch 379, change: 0.13324523\n",
      "Epoch 380, change: 0.12029198\n",
      "Epoch 381, change: 0.082298088\n",
      "Epoch 382, change: 0.11402257\n",
      "Epoch 383, change: 0.099254351\n",
      "Epoch 384, change: 0.084912762\n",
      "Epoch 385, change: 0.10105754\n",
      "Epoch 386, change: 0.10565951\n",
      "Epoch 387, change: 0.064803442\n",
      "Epoch 388, change: 0.084910229\n",
      "Epoch 389, change: 0.079820333\n",
      "Epoch 390, change: 0.075993362\n",
      "Epoch 391, change: 0.091783214\n",
      "Epoch 392, change: 0.10803142\n",
      "Epoch 393, change: 0.093592361\n",
      "Epoch 394, change: 0.11677894\n",
      "Epoch 395, change: 0.12623357\n",
      "Epoch 396, change: 0.085461979\n",
      "Epoch 397, change: 0.080221878\n",
      "Epoch 398, change: 0.13858014\n",
      "Epoch 399, change: 0.11608078\n",
      "Epoch 400, change: 0.088206702\n",
      "Epoch 401, change: 0.11391832\n",
      "Epoch 402, change: 0.09980671\n",
      "Epoch 403, change: 0.061264449\n",
      "Epoch 404, change: 0.13215082\n",
      "Epoch 405, change: 0.12201128\n",
      "Epoch 406, change: 0.1080502\n",
      "Epoch 407, change: 0.14577937\n",
      "Epoch 408, change: 0.12992162\n",
      "Epoch 409, change: 0.11286098\n",
      "Epoch 410, change: 0.079263803\n",
      "Epoch 411, change: 0.1072025\n",
      "Epoch 412, change: 0.093376705\n",
      "Epoch 413, change: 0.14292471\n",
      "Epoch 414, change: 0.11368312\n",
      "Epoch 415, change: 0.086700507\n",
      "Epoch 416, change: 0.099382423\n",
      "Epoch 417, change: 0.12096364\n",
      "Epoch 418, change: 0.11830995\n",
      "Epoch 419, change: 0.12174873\n",
      "Epoch 420, change: 0.13854338\n",
      "Epoch 421, change: 0.091272481\n",
      "Epoch 422, change: 0.12132021\n",
      "Epoch 423, change: 0.085056494\n",
      "Epoch 424, change: 0.14497335\n",
      "Epoch 425, change: 0.068873034\n",
      "Epoch 426, change: 0.11607613\n",
      "Epoch 427, change: 0.13417095\n",
      "Epoch 428, change: 0.13429777\n",
      "Epoch 429, change: 0.064163689\n",
      "Epoch 430, change: 0.14986026\n",
      "Epoch 431, change: 0.14031996\n",
      "Epoch 432, change: 0.10540225\n",
      "Epoch 433, change: 0.092187001\n",
      "Epoch 434, change: 0.1249628\n",
      "Epoch 435, change: 0.087056988\n",
      "Epoch 436, change: 0.13815243\n",
      "Epoch 437, change: 0.077053201\n",
      "Epoch 438, change: 0.074147657\n",
      "Epoch 439, change: 0.073384269\n",
      "Epoch 440, change: 0.090955326\n",
      "Epoch 441, change: 0.10281215\n",
      "Epoch 442, change: 0.11965689\n",
      "Epoch 443, change: 0.11447988\n",
      "Epoch 444, change: 0.11652721\n",
      "Epoch 445, change: 0.12814721\n",
      "Epoch 446, change: 0.11042792\n",
      "Epoch 447, change: 0.086518753\n",
      "Epoch 448, change: 0.12862456\n",
      "Epoch 449, change: 0.096518458\n",
      "Epoch 450, change: 0.077109715\n",
      "Epoch 451, change: 0.10864578\n",
      "Epoch 452, change: 0.14080112\n",
      "Epoch 453, change: 0.078743906\n",
      "Epoch 454, change: 0.13659354\n",
      "Epoch 455, change: 0.10822309\n",
      "Epoch 456, change: 0.11910114\n",
      "Epoch 457, change: 0.073755354\n",
      "Epoch 458, change: 0.12843991\n",
      "Epoch 459, change: 0.10323929\n",
      "Epoch 460, change: 0.13644086\n",
      "Epoch 461, change: 0.10814799\n",
      "Epoch 462, change: 0.096920504\n",
      "Epoch 463, change: 0.076934972\n",
      "Epoch 464, change: 0.10024816\n",
      "Epoch 465, change: 0.094815967\n",
      "Epoch 466, change: 0.092499875\n",
      "Epoch 467, change: 0.090796684\n",
      "Epoch 468, change: 0.12504027\n",
      "Epoch 469, change: 0.12580403\n",
      "Epoch 470, change: 0.11033161\n",
      "Epoch 471, change: 0.14239771\n",
      "Epoch 472, change: 0.088045025\n",
      "Epoch 473, change: 0.11544994\n",
      "Epoch 474, change: 0.12200175\n",
      "Epoch 475, change: 0.069657382\n",
      "Epoch 476, change: 0.10264294\n",
      "Epoch 477, change: 0.092732711\n",
      "Epoch 478, change: 0.10805252\n",
      "Epoch 479, change: 0.12205373\n",
      "Epoch 480, change: 0.11920434\n",
      "Epoch 481, change: 0.10853823\n",
      "Epoch 482, change: 0.13494206\n",
      "Epoch 483, change: 0.11405097\n",
      "Epoch 484, change: 0.10933206\n",
      "Epoch 485, change: 0.07413401\n",
      "Epoch 486, change: 0.095403265\n",
      "Epoch 487, change: 0.08328391\n",
      "Epoch 488, change: 0.11966752\n",
      "Epoch 489, change: 0.059312683\n",
      "Epoch 490, change: 0.094146568\n",
      "Epoch 491, change: 0.12140305\n",
      "Epoch 492, change: 0.11151324\n",
      "Epoch 493, change: 0.080849463\n",
      "Epoch 494, change: 0.12672698\n",
      "Epoch 495, change: 0.11893203\n",
      "Epoch 496, change: 0.071909622\n",
      "Epoch 497, change: 0.11963259\n",
      "Epoch 498, change: 0.077776267\n",
      "Epoch 499, change: 0.083793211\n",
      "Epoch 500, change: 0.12009932\n",
      "Epoch 501, change: 0.076244231\n",
      "Epoch 502, change: 0.1019096\n",
      "Epoch 503, change: 0.088295567\n",
      "Epoch 504, change: 0.084989699\n",
      "Epoch 505, change: 0.11021641\n",
      "Epoch 506, change: 0.16175504\n",
      "Epoch 507, change: 0.14374312\n",
      "Epoch 508, change: 0.1098835\n",
      "Epoch 509, change: 0.12108463\n",
      "Epoch 510, change: 0.13358164\n",
      "Epoch 511, change: 0.080056769\n",
      "Epoch 512, change: 0.070991967\n",
      "Epoch 513, change: 0.11060316\n",
      "Epoch 514, change: 0.15244876\n",
      "Epoch 515, change: 0.11349555\n",
      "Epoch 516, change: 0.10732973\n",
      "Epoch 517, change: 0.084353685\n",
      "Epoch 518, change: 0.12158651\n",
      "Epoch 519, change: 0.10602396\n",
      "Epoch 520, change: 0.094955726\n",
      "Epoch 521, change: 0.098887438\n",
      "Epoch 522, change: 0.10267291\n",
      "Epoch 523, change: 0.12812532\n",
      "Epoch 524, change: 0.11566614\n",
      "Epoch 525, change: 0.093847061\n",
      "Epoch 526, change: 0.14301149\n",
      "Epoch 527, change: 0.12646314\n",
      "Epoch 528, change: 0.10586016\n",
      "Epoch 529, change: 0.099740052\n",
      "Epoch 530, change: 0.11504739\n",
      "Epoch 531, change: 0.086634483\n",
      "Epoch 532, change: 0.12330973\n",
      "Epoch 533, change: 0.13261958\n",
      "Epoch 534, change: 0.12218601\n",
      "Epoch 535, change: 0.10564846\n",
      "Epoch 536, change: 0.10857717\n",
      "Epoch 537, change: 0.081026537\n",
      "Epoch 538, change: 0.085096297\n",
      "Epoch 539, change: 0.14245002\n",
      "Epoch 540, change: 0.10582252\n",
      "Epoch 541, change: 0.11768326\n",
      "Epoch 542, change: 0.10545528\n",
      "Epoch 543, change: 0.084258235\n",
      "Epoch 544, change: 0.07699993\n",
      "Epoch 545, change: 0.14381101\n",
      "Epoch 546, change: 0.12952731\n",
      "Epoch 547, change: 0.10633112\n",
      "Epoch 548, change: 0.15016523\n",
      "Epoch 549, change: 0.074193711\n",
      "Epoch 550, change: 0.080713806\n",
      "Epoch 551, change: 0.069556052\n",
      "Epoch 552, change: 0.12032882\n",
      "Epoch 553, change: 0.10206863\n",
      "Epoch 554, change: 0.10070576\n",
      "Epoch 555, change: 0.073467721\n",
      "Epoch 556, change: 0.08281014\n",
      "Epoch 557, change: 0.15083096\n",
      "Epoch 558, change: 0.084413285\n",
      "Epoch 559, change: 0.12517807\n",
      "Epoch 560, change: 0.10572613\n",
      "Epoch 561, change: 0.1297668\n",
      "Epoch 562, change: 0.11861193\n",
      "Epoch 563, change: 0.10241944\n",
      "Epoch 564, change: 0.095539541\n",
      "Epoch 565, change: 0.087936562\n",
      "Epoch 566, change: 0.12644949\n",
      "Epoch 567, change: 0.086512655\n",
      "Epoch 568, change: 0.1108017\n",
      "Epoch 569, change: 0.13117332\n",
      "Epoch 570, change: 0.073400074\n",
      "Epoch 571, change: 0.073386568\n",
      "Epoch 572, change: 0.12435542\n",
      "Epoch 573, change: 0.11735217\n",
      "Epoch 574, change: 0.085812582\n",
      "Epoch 575, change: 0.11255681\n",
      "Epoch 576, change: 0.076754769\n",
      "Epoch 577, change: 0.091142842\n",
      "Epoch 578, change: 0.1064433\n",
      "Epoch 579, change: 0.12645579\n",
      "Epoch 580, change: 0.067724312\n",
      "Epoch 581, change: 0.12039358\n",
      "Epoch 582, change: 0.069240048\n",
      "Epoch 583, change: 0.14318685\n",
      "Epoch 584, change: 0.10021784\n",
      "Epoch 585, change: 0.10811567\n",
      "Epoch 586, change: 0.10184966\n",
      "Epoch 587, change: 0.12317643\n",
      "Epoch 588, change: 0.074417901\n",
      "Epoch 589, change: 0.073845391\n",
      "Epoch 590, change: 0.087824077\n",
      "Epoch 591, change: 0.10956806\n",
      "Epoch 592, change: 0.083710469\n",
      "Epoch 593, change: 0.10266048\n",
      "Epoch 594, change: 0.11015176\n",
      "Epoch 595, change: 0.083546096\n",
      "Epoch 596, change: 0.091037552\n",
      "Epoch 597, change: 0.10803585\n",
      "Epoch 598, change: 0.079722661\n",
      "Epoch 599, change: 0.12164571\n",
      "Epoch 600, change: 0.08279424\n",
      "Epoch 601, change: 0.11180839\n",
      "Epoch 602, change: 0.10135294\n",
      "Epoch 603, change: 0.11873818\n",
      "Epoch 604, change: 0.13081957\n",
      "Epoch 605, change: 0.098618605\n",
      "Epoch 606, change: 0.083035022\n",
      "Epoch 607, change: 0.11252327\n",
      "Epoch 608, change: 0.13730253\n",
      "Epoch 609, change: 0.11601168\n",
      "Epoch 610, change: 0.10709986\n",
      "Epoch 611, change: 0.093532442\n",
      "Epoch 612, change: 0.11042468\n",
      "Epoch 613, change: 0.12176496\n",
      "Epoch 614, change: 0.097442823\n",
      "Epoch 615, change: 0.091991434\n",
      "Epoch 616, change: 0.089897264\n",
      "Epoch 617, change: 0.12509977\n",
      "Epoch 618, change: 0.14500373\n",
      "Epoch 619, change: 0.074621295\n",
      "Epoch 620, change: 0.097087139\n",
      "Epoch 621, change: 0.15780938\n",
      "Epoch 622, change: 0.1206716\n",
      "Epoch 623, change: 0.065626398\n",
      "Epoch 624, change: 0.094908306\n",
      "Epoch 625, change: 0.10692653\n",
      "Epoch 626, change: 0.11503708\n",
      "Epoch 627, change: 0.081588852\n",
      "Epoch 628, change: 0.10892676\n",
      "Epoch 629, change: 0.13074087\n",
      "Epoch 630, change: 0.10262529\n",
      "Epoch 631, change: 0.087850874\n",
      "Epoch 632, change: 0.075759905\n",
      "Epoch 633, change: 0.10488551\n",
      "Epoch 634, change: 0.11450064\n",
      "Epoch 635, change: 0.085142529\n",
      "Epoch 636, change: 0.071244505\n",
      "Epoch 637, change: 0.12077347\n",
      "Epoch 638, change: 0.13348097\n",
      "Epoch 639, change: 0.11011069\n",
      "Epoch 640, change: 0.13392325\n",
      "Epoch 641, change: 0.087138277\n",
      "Epoch 642, change: 0.081708491\n",
      "Epoch 643, change: 0.097430054\n",
      "Epoch 644, change: 0.1061732\n",
      "Epoch 645, change: 0.085329017\n",
      "Epoch 646, change: 0.12226192\n",
      "Epoch 647, change: 0.10249984\n",
      "Epoch 648, change: 0.083546876\n",
      "Epoch 649, change: 0.099476302\n",
      "Epoch 650, change: 0.11600686\n",
      "Epoch 651, change: 0.16586509\n",
      "Epoch 652, change: 0.10977892\n",
      "Epoch 653, change: 0.14275323\n",
      "Epoch 654, change: 0.10082666\n",
      "Epoch 655, change: 0.14869404\n",
      "Epoch 656, change: 0.077562673\n",
      "Epoch 657, change: 0.094948311\n",
      "Epoch 658, change: 0.068563435\n",
      "Epoch 659, change: 0.083366978\n",
      "Epoch 660, change: 0.088681784\n",
      "Epoch 661, change: 0.082133681\n",
      "Epoch 662, change: 0.11564943\n",
      "Epoch 663, change: 0.10457929\n",
      "Epoch 664, change: 0.096467422\n",
      "Epoch 665, change: 0.096490292\n",
      "Epoch 666, change: 0.085444958\n",
      "Epoch 667, change: 0.1360747\n",
      "Epoch 668, change: 0.11875477\n",
      "Epoch 669, change: 0.14465095\n",
      "Epoch 670, change: 0.12504753\n",
      "Epoch 671, change: 0.14310926\n",
      "Epoch 672, change: 0.081677408\n",
      "Epoch 673, change: 0.095759826\n",
      "Epoch 674, change: 0.1495913\n",
      "Epoch 675, change: 0.11624628\n",
      "Epoch 676, change: 0.073455533\n",
      "Epoch 677, change: 0.16434639\n",
      "Epoch 678, change: 0.12182774\n",
      "Epoch 679, change: 0.12525332\n",
      "Epoch 680, change: 0.073557187\n",
      "Epoch 681, change: 0.13368506\n",
      "Epoch 682, change: 0.13474303\n",
      "Epoch 683, change: 0.11202017\n",
      "Epoch 684, change: 0.11680469\n",
      "Epoch 685, change: 0.1276875\n",
      "Epoch 686, change: 0.10887837\n",
      "Epoch 687, change: 0.10008458\n",
      "Epoch 688, change: 0.12933693\n",
      "Epoch 689, change: 0.10519352\n",
      "Epoch 690, change: 0.093326849\n",
      "Epoch 691, change: 0.07577501\n",
      "Epoch 692, change: 0.13150672\n",
      "Epoch 693, change: 0.086519466\n",
      "Epoch 694, change: 0.075578645\n",
      "Epoch 695, change: 0.097307712\n",
      "Epoch 696, change: 0.083259408\n",
      "Epoch 697, change: 0.084599855\n",
      "Epoch 698, change: 0.092975129\n",
      "Epoch 699, change: 0.10376927\n",
      "Epoch 700, change: 0.11965548\n",
      "Epoch 701, change: 0.08372185\n",
      "Epoch 702, change: 0.069347216\n",
      "Epoch 703, change: 0.1424117\n",
      "Epoch 704, change: 0.12362135\n",
      "Epoch 705, change: 0.12134125\n",
      "Epoch 706, change: 0.095320842\n",
      "Epoch 707, change: 0.11692303\n",
      "Epoch 708, change: 0.12346042\n",
      "Epoch 709, change: 0.1273926\n",
      "Epoch 710, change: 0.14650166\n",
      "Epoch 711, change: 0.14357295\n",
      "Epoch 712, change: 0.07481792\n",
      "Epoch 713, change: 0.12302996\n",
      "Epoch 714, change: 0.10096276\n",
      "Epoch 715, change: 0.12691131\n",
      "Epoch 716, change: 0.12448248\n",
      "Epoch 717, change: 0.10897637\n",
      "Epoch 718, change: 0.087897523\n",
      "Epoch 719, change: 0.074255237\n",
      "Epoch 720, change: 0.10579983\n",
      "Epoch 721, change: 0.10458503\n",
      "Epoch 722, change: 0.13264015\n",
      "Epoch 723, change: 0.10459842\n",
      "Epoch 724, change: 0.13932433\n",
      "Epoch 725, change: 0.093105311\n",
      "Epoch 726, change: 0.1273762\n",
      "Epoch 727, change: 0.12772881\n",
      "Epoch 728, change: 0.083095969\n",
      "Epoch 729, change: 0.10866698\n",
      "Epoch 730, change: 0.13887529\n",
      "Epoch 731, change: 0.075329379\n",
      "Epoch 732, change: 0.13932939\n",
      "Epoch 733, change: 0.11913303\n",
      "Epoch 734, change: 0.093373512\n",
      "Epoch 735, change: 0.082982065\n",
      "Epoch 736, change: 0.084248211\n",
      "Epoch 737, change: 0.066180294\n",
      "Epoch 738, change: 0.094178748\n",
      "Epoch 739, change: 0.10869721\n",
      "Epoch 740, change: 0.08384873\n",
      "Epoch 741, change: 0.12039509\n",
      "Epoch 742, change: 0.10480646\n",
      "Epoch 743, change: 0.14912767\n",
      "Epoch 744, change: 0.08378462\n",
      "Epoch 745, change: 0.093002039\n",
      "Epoch 746, change: 0.12432388\n",
      "Epoch 747, change: 0.09972515\n",
      "Epoch 748, change: 0.11516367\n",
      "Epoch 749, change: 0.13012325\n",
      "Epoch 750, change: 0.07127615\n",
      "Epoch 751, change: 0.070187501\n",
      "Epoch 752, change: 0.089674288\n",
      "Epoch 753, change: 0.087541998\n",
      "Epoch 754, change: 0.15287565\n",
      "Epoch 755, change: 0.10596098\n",
      "Epoch 756, change: 0.1210996\n",
      "Epoch 757, change: 0.13728521\n",
      "Epoch 758, change: 0.07073029\n",
      "Epoch 759, change: 0.13310494\n",
      "Epoch 760, change: 0.14576776\n",
      "Epoch 761, change: 0.11745297\n",
      "Epoch 762, change: 0.11770315\n",
      "Epoch 763, change: 0.071006123\n",
      "Epoch 764, change: 0.077984278\n",
      "Epoch 765, change: 0.093434352\n",
      "Epoch 766, change: 0.13815409\n",
      "Epoch 767, change: 0.083795699\n",
      "Epoch 768, change: 0.12001116\n",
      "Epoch 769, change: 0.14366332\n",
      "Epoch 770, change: 0.12186737\n",
      "Epoch 771, change: 0.1063473\n",
      "Epoch 772, change: 0.12419051\n",
      "Epoch 773, change: 0.12890229\n",
      "Epoch 774, change: 0.11857932\n",
      "Epoch 775, change: 0.1060815\n",
      "Epoch 776, change: 0.10981615\n",
      "Epoch 777, change: 0.11354393\n",
      "Epoch 778, change: 0.12855282\n",
      "Epoch 779, change: 0.1115999\n",
      "Epoch 780, change: 0.061040923\n",
      "Epoch 781, change: 0.089544565\n",
      "Epoch 782, change: 0.116208\n",
      "Epoch 783, change: 0.11093787\n",
      "Epoch 784, change: 0.099104889\n",
      "Epoch 785, change: 0.13568324\n",
      "Epoch 786, change: 0.10500776\n",
      "Epoch 787, change: 0.079531729\n",
      "Epoch 788, change: 0.11672028\n",
      "Epoch 789, change: 0.099488567\n",
      "Epoch 790, change: 0.14245366\n",
      "Epoch 791, change: 0.092317141\n",
      "Epoch 792, change: 0.12337287\n",
      "Epoch 793, change: 0.11186344\n",
      "Epoch 794, change: 0.082086118\n",
      "Epoch 795, change: 0.14685353\n",
      "Epoch 796, change: 0.078084103\n",
      "Epoch 797, change: 0.1175479\n",
      "Epoch 798, change: 0.13773254\n",
      "Epoch 799, change: 0.11814612\n",
      "Epoch 800, change: 0.10447066\n",
      "Epoch 801, change: 0.1556868\n",
      "Epoch 802, change: 0.12936972\n",
      "Epoch 803, change: 0.10375703\n",
      "Epoch 804, change: 0.08178801\n",
      "Epoch 805, change: 0.090645092\n",
      "Epoch 806, change: 0.10212109\n",
      "Epoch 807, change: 0.13121546\n",
      "Epoch 808, change: 0.089559319\n",
      "Epoch 809, change: 0.078806592\n",
      "Epoch 810, change: 0.15098479\n",
      "Epoch 811, change: 0.06192212\n",
      "Epoch 812, change: 0.13705983\n",
      "Epoch 813, change: 0.1157896\n",
      "Epoch 814, change: 0.11229846\n",
      "Epoch 815, change: 0.1391406\n",
      "Epoch 816, change: 0.13010737\n",
      "Epoch 817, change: 0.096459994\n",
      "Epoch 818, change: 0.11635582\n",
      "Epoch 819, change: 0.11866563\n",
      "Epoch 820, change: 0.11605154\n",
      "Epoch 821, change: 0.091750195\n",
      "Epoch 822, change: 0.11051183\n",
      "Epoch 823, change: 0.11589425\n",
      "Epoch 824, change: 0.085363784\n",
      "Epoch 825, change: 0.12928468\n",
      "Epoch 826, change: 0.091840979\n",
      "Epoch 827, change: 0.076355207\n",
      "Epoch 828, change: 0.068003182\n",
      "Epoch 829, change: 0.13778475\n",
      "Epoch 830, change: 0.099576566\n",
      "Epoch 831, change: 0.12520317\n",
      "Epoch 832, change: 0.12835859\n",
      "Epoch 833, change: 0.13758098\n",
      "Epoch 834, change: 0.12190042\n",
      "Epoch 835, change: 0.093581228\n",
      "Epoch 836, change: 0.11377228\n",
      "Epoch 837, change: 0.14432836\n",
      "Epoch 838, change: 0.072804573\n",
      "Epoch 839, change: 0.14382758\n",
      "Epoch 840, change: 0.080461343\n",
      "Epoch 841, change: 0.10184449\n",
      "Epoch 842, change: 0.083300879\n",
      "Epoch 843, change: 0.098643469\n",
      "Epoch 844, change: 0.12193042\n",
      "Epoch 845, change: 0.10740331\n",
      "Epoch 846, change: 0.13642545\n",
      "Epoch 847, change: 0.071453068\n",
      "Epoch 848, change: 0.11816858\n",
      "Epoch 849, change: 0.095908174\n",
      "Epoch 850, change: 0.097598311\n",
      "Epoch 851, change: 0.11767227\n",
      "Epoch 852, change: 0.13520387\n",
      "Epoch 853, change: 0.1103507\n",
      "Epoch 854, change: 0.10728371\n",
      "Epoch 855, change: 0.10578348\n",
      "Epoch 856, change: 0.080577852\n",
      "Epoch 857, change: 0.12846002\n",
      "Epoch 858, change: 0.11973686\n",
      "Epoch 859, change: 0.076959057\n",
      "Epoch 860, change: 0.10468722\n",
      "Epoch 861, change: 0.087367391\n",
      "Epoch 862, change: 0.11370665\n",
      "Epoch 863, change: 0.10924959\n",
      "Epoch 864, change: 0.090117076\n",
      "Epoch 865, change: 0.10856944\n",
      "Epoch 866, change: 0.10841123\n",
      "Epoch 867, change: 0.12200777\n",
      "Epoch 868, change: 0.14216944\n",
      "Epoch 869, change: 0.083551061\n",
      "Epoch 870, change: 0.090713156\n",
      "Epoch 871, change: 0.13377939\n",
      "Epoch 872, change: 0.13661616\n",
      "Epoch 873, change: 0.11220962\n",
      "Epoch 874, change: 0.11263436\n",
      "Epoch 875, change: 0.10845376\n",
      "Epoch 876, change: 0.096201145\n",
      "Epoch 877, change: 0.12886736\n",
      "Epoch 878, change: 0.077524503\n",
      "Epoch 879, change: 0.13511235\n",
      "Epoch 880, change: 0.12445244\n",
      "Epoch 881, change: 0.11959742\n",
      "Epoch 882, change: 0.10710932\n",
      "Epoch 883, change: 0.061964513\n",
      "Epoch 884, change: 0.09450775\n",
      "Epoch 885, change: 0.15020199\n",
      "Epoch 886, change: 0.13044548\n",
      "Epoch 887, change: 0.11757168\n",
      "Epoch 888, change: 0.082090422\n",
      "Epoch 889, change: 0.11654572\n",
      "Epoch 890, change: 0.125432\n",
      "Epoch 891, change: 0.088731519\n",
      "Epoch 892, change: 0.088484891\n",
      "Epoch 893, change: 0.16112647\n",
      "Epoch 894, change: 0.10417385\n",
      "Epoch 895, change: 0.12820475\n",
      "Epoch 896, change: 0.090767213\n",
      "Epoch 897, change: 0.075462803\n",
      "Epoch 898, change: 0.12855148\n",
      "Epoch 899, change: 0.081011\n",
      "Epoch 900, change: 0.15805144\n",
      "Epoch 901, change: 0.062656672\n",
      "Epoch 902, change: 0.11672174\n",
      "Epoch 903, change: 0.068453824\n",
      "Epoch 904, change: 0.136368\n",
      "Epoch 905, change: 0.084272769\n",
      "Epoch 906, change: 0.088903632\n",
      "Epoch 907, change: 0.13310836\n",
      "Epoch 908, change: 0.075376227\n",
      "Epoch 909, change: 0.08925246\n",
      "Epoch 910, change: 0.10228733\n",
      "Epoch 911, change: 0.077011004\n",
      "Epoch 912, change: 0.15501847\n",
      "Epoch 913, change: 0.12020385\n",
      "Epoch 914, change: 0.12199787\n",
      "Epoch 915, change: 0.10374747\n",
      "Epoch 916, change: 0.10426846\n",
      "Epoch 917, change: 0.081290757\n",
      "Epoch 918, change: 0.12149644\n",
      "Epoch 919, change: 0.085934233\n",
      "Epoch 920, change: 0.11222215\n",
      "Epoch 921, change: 0.10312395\n",
      "Epoch 922, change: 0.1413814\n",
      "Epoch 923, change: 0.1011725\n",
      "Epoch 924, change: 0.11009963\n",
      "Epoch 925, change: 0.11430249\n",
      "Epoch 926, change: 0.077322436\n",
      "Epoch 927, change: 0.093845096\n",
      "Epoch 928, change: 0.097206323\n",
      "Epoch 929, change: 0.1103859\n",
      "Epoch 930, change: 0.080788835\n",
      "Epoch 931, change: 0.070805731\n",
      "Epoch 932, change: 0.091297867\n",
      "Epoch 933, change: 0.078935898\n",
      "Epoch 934, change: 0.15873587\n",
      "Epoch 935, change: 0.12863628\n",
      "Epoch 936, change: 0.14028475\n",
      "Epoch 937, change: 0.081673224\n",
      "Epoch 938, change: 0.088067603\n",
      "Epoch 939, change: 0.11971834\n",
      "Epoch 940, change: 0.10398683\n",
      "Epoch 941, change: 0.12422988\n",
      "Epoch 942, change: 0.11980573\n",
      "Epoch 943, change: 0.093946656\n",
      "Epoch 944, change: 0.11537952\n",
      "Epoch 945, change: 0.095584408\n",
      "Epoch 946, change: 0.089912376\n",
      "Epoch 947, change: 0.12879245\n",
      "Epoch 948, change: 0.11867422\n",
      "Epoch 949, change: 0.069490882\n",
      "Epoch 950, change: 0.068157291\n",
      "Epoch 951, change: 0.12256006\n",
      "Epoch 952, change: 0.11489707\n",
      "Epoch 953, change: 0.11413817\n",
      "Epoch 954, change: 0.10406668\n",
      "Epoch 955, change: 0.076670475\n",
      "Epoch 956, change: 0.14896086\n",
      "Epoch 957, change: 0.15746124\n",
      "Epoch 958, change: 0.13597979\n",
      "Epoch 959, change: 0.070855994\n",
      "Epoch 960, change: 0.12016481\n",
      "Epoch 961, change: 0.11574896\n",
      "Epoch 962, change: 0.11349085\n",
      "Epoch 963, change: 0.11713384\n",
      "Epoch 964, change: 0.067997208\n",
      "Epoch 965, change: 0.12818855\n",
      "Epoch 966, change: 0.10541711\n",
      "Epoch 967, change: 0.072807791\n",
      "Epoch 968, change: 0.075459769\n",
      "Epoch 969, change: 0.10849057\n",
      "Epoch 970, change: 0.099126961\n",
      "Epoch 971, change: 0.069247485\n",
      "Epoch 972, change: 0.090201256\n",
      "Epoch 973, change: 0.11070477\n",
      "Epoch 974, change: 0.085445822\n",
      "Epoch 975, change: 0.11006144\n",
      "Epoch 976, change: 0.13389564\n",
      "Epoch 977, change: 0.090276653\n",
      "Epoch 978, change: 0.12537038\n",
      "Epoch 979, change: 0.12183246\n",
      "Epoch 980, change: 0.1503231\n",
      "Epoch 981, change: 0.0880894\n",
      "Epoch 982, change: 0.11340571\n",
      "Epoch 983, change: 0.076718117\n",
      "Epoch 984, change: 0.13121406\n",
      "Epoch 985, change: 0.094364128\n",
      "Epoch 986, change: 0.10634922\n",
      "Epoch 987, change: 0.071044527\n",
      "Epoch 988, change: 0.10416804\n",
      "Epoch 989, change: 0.14486183\n",
      "Epoch 990, change: 0.096103425\n",
      "Epoch 991, change: 0.097402414\n",
      "Epoch 992, change: 0.088947294\n",
      "Epoch 993, change: 0.1110488\n",
      "Epoch 994, change: 0.073638447\n",
      "Epoch 995, change: 0.06820608\n",
      "Epoch 996, change: 0.10637479\n",
      "Epoch 997, change: 0.066750826\n",
      "Epoch 998, change: 0.13068771\n",
      "Epoch 999, change: 0.065807765\n",
      "max_iter reached after 351 secondsEpoch 1000, change: 0.15814228\n",
      "\n",
      "==> Treinando... OK\n",
      "==> Classificando no teste: 9,528 tickets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gosoares/dev/ticket-classifier/.venv/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas (TF-IDF + LogisticRegression)\n",
      "  accuracy:    0.8593\n",
      "  f1_macro:    0.8605\n",
      "  f1_weighted: 0.8594\n"
     ]
    }
   ],
   "source": [
    "tfidf_logreg = TfidfClassifier.logistic_regression(\n",
    "    random_state=RANDOM_STATE, verbose=SKLEARN_VERBOSE\n",
    ")\n",
    "tfidf_logreg_metrics, tfidf_logreg_pred = evaluate_classifier(tfidf_logreg)\n",
    "print_metrics(tfidf_logreg_metrics, tfidf_logreg.name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9e3b4b",
   "metadata": {},
   "source": [
    "### TF-IDF + SGDClassifier\n",
    "\n",
    "O **SGDClassifier** treina um modelo linear com *Stochastic Gradient Descent*, sendo eficiente em datasets grandes. Dependendo da loss configurada, ele pode aproximar um SVM (hinge) ou uma regressão logística (log loss).\n",
    "\n",
    "É uma boa opção quando queremos velocidade e flexibilidade, mantendo a força dos modelos lineares em TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "912019ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> TF-IDF + SGDClassifier\n",
      "==> Treinando...\n",
      "-- Epoch 1\n",
      "Norm: 12.56, NNZs: 153105, Bias: -1.997780, T: 38109, Avg. loss: 0.128298, Objective: 0.130756\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 3.67, NNZs: 153105, Bias: -2.103788, T: 76218, Avg. loss: 0.117734, Objective: 0.119750\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 3.66, NNZs: 153105, Bias: -2.149386, T: 114327, Avg. loss: 0.116678, Objective: 0.118645\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 8.73, NNZs: 153105, Bias: -2.171614, T: 152436, Avg. loss: 0.116213, Objective: 0.118146\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 9.89, NNZs: 153105, Bias: -2.200554, T: 190545, Avg. loss: 0.115664, Objective: 0.117601\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 4.22, NNZs: 153105, Bias: -2.223582, T: 228654, Avg. loss: 0.115389, Objective: 0.117322\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 9.04, NNZs: 153105, Bias: -2.237853, T: 266763, Avg. loss: 0.115299, Objective: 0.117227\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 3.51, NNZs: 153105, Bias: -2.247963, T: 304872, Avg. loss: 0.115192, Objective: 0.117116\n",
      "Total training time: 0.29 seconds.\n",
      "Convergence after 8 epochs took 0.29 seconds\n",
      "-- Epoch 1\n",
      "Norm: 6.82, NNZs: 153105, Bias: -2.139909, T: 38109, Avg. loss: 0.073781, Objective: 0.077618\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 4.52, NNZs: 153105, Bias: -2.240431, T: 76218, Avg. loss: 0.055995, Objective: 0.058249\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 6.81, NNZs: 153105, Bias: -2.284757, T: 114327, Avg. loss: 0.054153, Objective: 0.056260\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 6.11, NNZs: 153105, Bias: -2.332933, T: 152436, Avg. loss: 0.053986, Objective: 0.056036\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 6.31, NNZs: 153105, Bias: -2.353029, T: 190545, Avg. loss: 0.053177, Objective: 0.055190\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 6.18, NNZs: 153105, Bias: -2.368039, T: 228654, Avg. loss: 0.053058, Objective: 0.055053\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 7.66, NNZs: 153105, Bias: -2.396282, T: 266763, Avg. loss: 0.053399, Objective: 0.055392\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 6.19, NNZs: 153105, Bias: -2.407460, T: 304872, Avg. loss: 0.052828, Objective: 0.054818\n",
      "Total training time: 0.29 seconds.\n",
      "Convergence after 8 epochs took 0.29 seconds\n",
      "-- Epoch 1\n",
      "Norm: 6.99, NNZs: 153105, Bias: -1.827251, T: 38109, Avg. loss: 0.228316, Objective: 0.230859\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 3.51, NNZs: 153105, Bias: -1.911086, T: 76218, Avg. loss: 0.211193, Objective: 0.213423\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 6.27, NNZs: 153105, Bias: -1.957677, T: 114327, Avg. loss: 0.209427, Objective: 0.211634\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 6.78, NNZs: 153105, Bias: -1.983093, T: 152436, Avg. loss: 0.208568, Objective: 0.210782\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 10.72, NNZs: 153105, Bias: -1.997708, T: 190545, Avg. loss: 0.208583, Objective: 0.210785\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 4.00, NNZs: 153105, Bias: -2.021430, T: 228654, Avg. loss: 0.207577, Objective: 0.209775\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 11.85, NNZs: 153105, Bias: -2.028334, T: 266763, Avg. loss: 0.208050, Objective: 0.210256\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 10.09, NNZs: 153105, Bias: -2.040635, T: 304872, Avg. loss: 0.207568, Objective: 0.209771\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 6.48, NNZs: 153105, Bias: -2.046418, T: 342981, Avg. loss: 0.207777, Objective: 0.209978\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 5.72, NNZs: 153105, Bias: -2.054497, T: 381090, Avg. loss: 0.207481, Objective: 0.209684\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 5.80, NNZs: 153105, Bias: -2.059852, T: 419199, Avg. loss: 0.207553, Objective: 0.209759\n",
      "Total training time: 0.38 seconds.\n",
      "Convergence after 11 epochs took 0.38 seconds\n",
      "-- Epoch 1\n",
      "Norm: 4.53, NNZs: 153105, Bias: -1.522515, T: 38109, Avg. loss: 0.311775, Objective: 0.314097\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 7.72, NNZs: 153105, Bias: -1.594362, T: 76218, Avg. loss: 0.289458, Objective: 0.291440\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 5.19, NNZs: 153105, Bias: -1.611275, T: 114327, Avg. loss: 0.287673, Objective: 0.289625\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 10.38, NNZs: 153105, Bias: -1.640172, T: 152436, Avg. loss: 0.285800, Objective: 0.287734\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3.65, NNZs: 153105, Bias: -1.647792, T: 190545, Avg. loss: 0.286140, Objective: 0.288056\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 4.40, NNZs: 153105, Bias: -1.652685, T: 228654, Avg. loss: 0.285633, Objective: 0.287554\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 6.81, NNZs: 153105, Bias: -1.660256, T: 266763, Avg. loss: 0.285046, Objective: 0.286975\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 10.27, NNZs: 153105, Bias: -1.670638, T: 304872, Avg. loss: 0.284604, Objective: 0.286519\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 4.10, NNZs: 153105, Bias: -1.676821, T: 342981, Avg. loss: 0.284562, Objective: 0.286480\n",
      "Total training time: 0.32 seconds.\n",
      "Convergence after 9 epochs took 0.32 seconds\n",
      "-- Epoch 1\n",
      "Norm: 4.94, NNZs: 153105, Bias: -2.516723, T: 38109, Avg. loss: 0.060812, Objective: 0.064036\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5.31, NNZs: 153105, Bias: -2.650572, T: 76218, Avg. loss: 0.048057, Objective: 0.050086\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.04, NNZs: 153105, Bias: -2.720966, T: 114327, Avg. loss: 0.046708, Objective: 0.048677\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 9.75, NNZs: 153105, Bias: -2.761655, T: 152436, Avg. loss: 0.046126, Objective: 0.048072\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 6.04, NNZs: 153105, Bias: -2.781670, T: 190545, Avg. loss: 0.045753, Objective: 0.047654\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 5.11, NNZs: 153105, Bias: -2.822090, T: 228654, Avg. loss: 0.046053, Objective: 0.047958\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 4.42, NNZs: 153105, Bias: -2.835647, T: 266763, Avg. loss: 0.045429, Objective: 0.047327\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 7.39, NNZs: 153105, Bias: -2.856283, T: 304872, Avg. loss: 0.045668, Objective: 0.047554\n",
      "Total training time: 0.28 seconds.\n",
      "Convergence after 8 epochs took 0.28 seconds\n",
      "-- Epoch 1\n",
      "Norm: 3.74, NNZs: 153105, Bias: -1.673026, T: 38109, Avg. loss: 0.163878, Objective: 0.166931\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 6.00, NNZs: 153105, Bias: -1.751802, T: 76218, Avg. loss: 0.149593, Objective: 0.152099\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.58, NNZs: 153105, Bias: -1.790839, T: 114327, Avg. loss: 0.147636, Objective: 0.150126\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 7.71, NNZs: 153105, Bias: -1.813946, T: 152436, Avg. loss: 0.146976, Objective: 0.149445\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 7.23, NNZs: 153105, Bias: -1.832135, T: 190545, Avg. loss: 0.146612, Objective: 0.149062\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.08, NNZs: 153105, Bias: -1.840940, T: 228654, Avg. loss: 0.146282, Objective: 0.148740\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 7.04, NNZs: 153105, Bias: -1.855169, T: 266763, Avg. loss: 0.145986, Objective: 0.148445\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 5.58, NNZs: 153105, Bias: -1.862849, T: 304872, Avg. loss: 0.145939, Objective: 0.148386\n",
      "Total training time: 0.28 seconds.\n",
      "Convergence after 8 epochs took 0.28 seconds\n",
      "-- Epoch 1\n",
      "Norm: 6.05, NNZs: 153105, Bias: -2.548581, T: 38109, Avg. loss: 0.038550, Objective: 0.040905\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 13.03, NNZs: 153105, Bias: -2.678859, T: 76218, Avg. loss: 0.031439, Objective: 0.032965\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 3.63, NNZs: 153105, Bias: -2.760752, T: 114327, Avg. loss: 0.030602, Objective: 0.032064\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.73, NNZs: 153105, Bias: -2.828020, T: 152436, Avg. loss: 0.030581, Objective: 0.032000\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.91, NNZs: 153105, Bias: -2.870832, T: 190545, Avg. loss: 0.030272, Objective: 0.031682\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 4.14, NNZs: 153105, Bias: -2.900037, T: 228654, Avg. loss: 0.030005, Objective: 0.031401\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 6.27, NNZs: 153105, Bias: -2.921179, T: 266763, Avg. loss: 0.029831, Objective: 0.031215\n",
      "Total training time: 0.25 seconds.\n",
      "Convergence after 7 epochs took 0.25 seconds\n",
      "-- Epoch 1\n",
      "Norm: 5.31, NNZs: 153105, Bias: -2.253041, T: 38109, Avg. loss: 0.058803, Objective: 0.061389\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 7.82, NNZs: 153105, Bias: -2.411806, T: 76218, Avg. loss: 0.048184, Objective: 0.049875\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 5.72, NNZs: 153105, Bias: -2.487103, T: 114327, Avg. loss: 0.047174, Objective: 0.048765\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.17, NNZs: 153105, Bias: -2.534904, T: 152436, Avg. loss: 0.046641, Objective: 0.048216\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3.06, NNZs: 153105, Bias: -2.579587, T: 190545, Avg. loss: 0.046577, Objective: 0.048130\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 10.34, NNZs: 153105, Bias: -2.600014, T: 228654, Avg. loss: 0.046159, Objective: 0.047706\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 5.83, NNZs: 153105, Bias: -2.616251, T: 266763, Avg. loss: 0.046074, Objective: 0.047601\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 4.16, NNZs: 153105, Bias: -2.638435, T: 304872, Avg. loss: 0.046155, Objective: 0.047678\n",
      "Total training time: 0.28 seconds.\n",
      "Convergence after 8 epochs took 0.28 seconds\n",
      "==> Treinando... OK\n",
      "==> Classificando no teste: 9,528 tickets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    2.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas (TF-IDF + SGDClassifier)\n",
      "  accuracy:    0.8546\n",
      "  f1_macro:    0.8581\n",
      "  f1_weighted: 0.8551\n"
     ]
    }
   ],
   "source": [
    "tfidf_sgd = TfidfClassifier.sgd_classifier(\n",
    "    random_state=RANDOM_STATE, verbose=SKLEARN_VERBOSE\n",
    ")\n",
    "tfidf_sgd_metrics, tfidf_sgd_pred = evaluate_classifier(tfidf_sgd)\n",
    "print_metrics(tfidf_sgd_metrics, tfidf_sgd.name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c5c073",
   "metadata": {},
   "source": [
    "### Comparação entre TF-IDF\n",
    "\n",
    "Selecionamos o melhor TF-IDF pelo F1 macro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "969012be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TF-IDF + LinearSVC</td>\n",
       "      <td>0.863665</td>\n",
       "      <td>0.864076</td>\n",
       "      <td>0.863950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TF-IDF + LogisticRegression</td>\n",
       "      <td>0.859257</td>\n",
       "      <td>0.860544</td>\n",
       "      <td>0.859427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TF-IDF + SGDClassifier</td>\n",
       "      <td>0.854639</td>\n",
       "      <td>0.858083</td>\n",
       "      <td>0.855086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        method  accuracy  f1_macro  f1_weighted\n",
       "0           TF-IDF + LinearSVC  0.863665  0.864076     0.863950\n",
       "1  TF-IDF + LogisticRegression  0.859257  0.860544     0.859427\n",
       "2       TF-IDF + SGDClassifier  0.854639  0.858083     0.855086"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_rows = [\n",
    "    {\n",
    "        \"method\": tfidf_linear.name,\n",
    "        \"accuracy\": tfidf_linear_metrics[\"accuracy\"],\n",
    "        \"f1_macro\": tfidf_linear_metrics[\"f1_macro\"],\n",
    "        \"f1_weighted\": tfidf_linear_metrics[\"f1_weighted\"],\n",
    "    },\n",
    "    {\n",
    "        \"method\": tfidf_logreg.name,\n",
    "        \"accuracy\": tfidf_logreg_metrics[\"accuracy\"],\n",
    "        \"f1_macro\": tfidf_logreg_metrics[\"f1_macro\"],\n",
    "        \"f1_weighted\": tfidf_logreg_metrics[\"f1_weighted\"],\n",
    "    },\n",
    "    {\n",
    "        \"method\": tfidf_sgd.name,\n",
    "        \"accuracy\": tfidf_sgd_metrics[\"accuracy\"],\n",
    "        \"f1_macro\": tfidf_sgd_metrics[\"f1_macro\"],\n",
    "        \"f1_weighted\": tfidf_sgd_metrics[\"f1_weighted\"],\n",
    "    },\n",
    "]\n",
    "\n",
    "tfidf_summary = pd.DataFrame(tfidf_rows).sort_values(\"f1_macro\", ascending=False)\n",
    "tfidf_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f9d470",
   "metadata": {},
   "source": [
    "Pelo conjunto de teste, o **TF-IDF + LinearSVC** foi o melhor entre os três modelos lineares (**F1 macro = 0.8641**, **accuracy = 0.8637**, **F1 weighted = 0.8639**), superando Logistic Regression e SGD por uma margem pequena, porém consistente.\n",
    "\n",
    "Esse resultado faz sentido porque o LinearSVC costuma ser particularmente forte em **vetores TF-IDF esparsos e de alta dimensão**, e o `class_weight=\"balanced\"` ajuda a manter um bom equilíbrio entre classes (o que aparece no F1 macro).\n",
    "\n",
    "A seguir, vamos manter o **mesmo classificador (LinearSVC)** e trocar apenas a representação de entrada: de TF-IDF para **embeddings**, para avaliar se a informação semântica traz ganho adicional.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88112805",
   "metadata": {},
   "source": [
    "### Embeddings + LinearSVC\n",
    "\n",
    "Em TF-IDF, o modelo depende muito de *tokens/n-grams* específicos. **Embeddings** (sentence-transformers) tentam capturar a **semântica** do texto em um vetor denso.\n",
    "\n",
    "A ideia aqui é simples: manter o mesmo tipo de classificador linear, mas trocar a representação do texto. Se o dataset tiver muitas variações lexicais para a mesma intenção, embeddings podem ajudar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81f04c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> Embeddings + LinearSVC\n",
      "==> Treinando...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14f2d2ea085c46759455a8c9dbb289f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1191 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]iter  1 act 2.078e+04 pre 2.078e+04 delta 6.721e-01 f 3.719e+04 |g| 6.184e+04 CG   1\n",
      "cg reaches trust region boundary\n",
      "iter  2 act 2.317e+03 pre 2.317e+03 delta 2.449e+00 f 1.641e+04 |g| 3.995e+03 CG   1\n",
      "cg reaches trust region boundary\n",
      "iter  3 act 4.844e+03 pre 4.519e+03 delta 3.137e+00 f 1.409e+04 |g| 4.949e+03 CG   2\n",
      "cg reaches trust region boundary\n",
      "iter  4 act 2.432e+03 pre 2.058e+03 delta 3.925e+00 f 9.250e+03 |g| 3.092e+03 CG   3\n",
      "iter  5 act 1.003e+03 pre 8.380e+02 delta 4.560e+00 f 6.818e+03 |g| 2.529e+03 CG   4\n",
      "cg reaches trust region boundary\n",
      "iter  6 act 4.488e+02 pre 3.931e+02 delta 5.482e+00 f 5.815e+03 |g| 1.267e+03 CG   5\n",
      "cg reaches trust region boundary\n",
      "iter  7 act 1.906e+02 pre 1.813e+02 delta 5.797e+00 f 5.366e+03 |g| 6.000e+02 CG   7\n",
      "iter  8 act 7.320e+01 pre 7.066e+01 delta 5.797e+00 f 5.176e+03 |g| 2.696e+02 CG  12\n",
      "iter  9 act 1.132e+01 pre 1.108e+01 delta 5.797e+00 f 5.102e+03 |g| 9.892e+01 CG  14\n",
      "iter 10 act 1.113e+00 pre 1.110e+00 delta 5.797e+00 f 5.091e+03 |g| 1.876e+01 CG  18\n",
      "iter 11 act 6.068e-02 pre 6.066e-02 delta 5.797e+00 f 5.090e+03 |g| 2.105e+00 CG  22\n",
      "iter  1 act 2.514e+04 pre 2.514e+04 delta 7.020e-01 f 4.148e+04 |g| 7.163e+04 CG   1\n",
      "cg reaches trust region boundary\n",
      "iter  2 act 3.082e+03 pre 3.082e+03 delta 1.843e+00 f 1.634e+04 |g| 5.425e+03 CG   1\n",
      "cg reaches trust region boundary\n",
      "iter  3 act 4.339e+03 pre 3.855e+03 delta 2.263e+00 f 1.326e+04 |g| 6.417e+03 CG   2\n",
      "cg reaches trust region boundary\n",
      "iter  4 act 2.210e+03 pre 1.970e+03 delta 2.776e+00 f 8.922e+03 |g| 4.849e+03 CG   3\n",
      "cg reaches trust region boundary\n",
      "iter  5 act 9.575e+02 pre 8.229e+02 delta 3.582e+00 f 6.713e+03 |g| 2.132e+03 CG   3\n",
      "cg reaches trust region boundary\n",
      "iter  6 act 5.242e+02 pre 4.691e+02 delta 4.411e+00 f 5.755e+03 |g| 1.024e+03 CG   4\n",
      "cg reaches trust region boundary\n",
      "iter  7 act 3.484e+02 pre 3.175e+02 delta 5.573e+00 f 5.231e+03 |g| 6.928e+02 CG   5\n",
      "cg reaches trust region boundary\n",
      "iter  8 act 1.975e+02 pre 1.770e+02 delta 6.546e+00 f 4.882e+03 |g| 4.296e+02 CG   7\n",
      "iter  9 act 8.404e+01 pre 8.114e+01 delta 6.546e+00 f 4.685e+03 |g| 2.841e+02 CG  11\n",
      "iter 10 act 8.608e+00 pre 8.510e+00 delta 6.546e+00 f 4.601e+03 |g| 1.128e+02 CG  11\n",
      "iter 11 act 2.922e+00 pre 2.914e+00 delta 6.546e+00 f 4.592e+03 |g| 1.710e+01 CG  19\n",
      "iter 12 act 3.972e-02 pre 3.972e-02 delta 6.546e+00 f 4.589e+03 |g| 3.142e+00 CG  18\n",
      "iter 13 act 1.978e-03 pre 1.978e-03 delta 6.546e+00 f 4.589e+03 |g| 3.125e-01 CG  25\n",
      "iter  1 act 1.769e+04 pre 1.769e+04 delta 6.480e-01 f 3.416e+04 |g| 5.459e+04 CG   1\n",
      "cg reaches trust region boundary\n",
      "iter  2 act 1.896e+03 pre 1.896e+03 delta 2.244e+00 f 1.647e+04 |g| 3.420e+03 CG   1\n",
      "cg reaches trust region boundary\n",
      "iter  3 act 3.669e+03 pre 3.470e+03 delta 2.795e+00 f 1.458e+04 |g| 4.214e+03 CG   2\n",
      "cg reaches trust region boundary\n",
      "iter  4 act 1.886e+03 pre 1.689e+03 delta 3.440e+00 f 1.091e+04 |g| 2.152e+03 CG   3\n",
      "cg reaches trust region boundary\n",
      "iter  5 act 9.164e+02 pre 7.892e+02 delta 4.216e+00 f 9.021e+03 |g| 1.877e+03 CG   3\n",
      "cg reaches trust region boundary\n",
      "iter  6 act 5.113e+02 pre 4.660e+02 delta 5.020e+00 f 8.105e+03 |g| 1.248e+03 CG   4\n",
      "cg reaches trust region boundary\n",
      "iter  7 act 2.734e+02 pre 2.517e+02 delta 5.648e+00 f 7.594e+03 |g| 6.727e+02 CG   7\n",
      "cg reaches trust region boundary\n",
      "iter  8 act 1.136e+02 pre 1.106e+02 delta 5.809e+00 f 7.320e+03 |g| 3.154e+02 CG  12\n",
      "iter  9 act 1.781e+01 pre 1.764e+01 delta 5.809e+00 f 7.207e+03 |g| 1.445e+02 CG  14\n",
      "iter 10 act 2.325e+00 pre 2.312e+00 delta 5.809e+00 f 7.189e+03 |g| 2.549e+01 CG  21\n",
      "iter 11 act 6.819e-02 pre 6.822e-02 delta 5.809e+00 f 7.187e+03 |g| 3.288e+00 CG  24\n",
      "iter  1 act 1.611e+04 pre 1.611e+04 delta 6.361e-01 f 3.200e+04 |g| 5.065e+04 CG   1\n",
      "cg reaches trust region boundary\n",
      "iter  2 act 1.561e+03 pre 1.561e+03 delta 1.940e+00 f 1.589e+04 |g| 2.936e+03 CG   1\n",
      "cg reaches trust region boundary\n",
      "iter  3 act 2.538e+03 pre 2.395e+03 delta 2.339e+00 f 1.433e+04 |g| 3.561e+03 CG   2\n",
      "cg reaches trust region boundary\n",
      "iter  4 act 1.356e+03 pre 1.242e+03 delta 2.940e+00 f 1.179e+04 |g| 1.837e+03 CG   3\n",
      "cg reaches trust region boundary\n",
      "iter  5 act 6.681e+02 pre 6.090e+02 delta 3.588e+00 f 1.043e+04 |g| 1.325e+03 CG   3\n",
      "cg reaches trust region boundary\n",
      "iter  6 act 3.985e+02 pre 3.761e+02 delta 3.871e+00 f 9.765e+03 |g| 8.413e+02 CG   4\n",
      "cg reaches trust region boundary\n",
      "iter  7 act 2.620e+02 pre 2.469e+02 delta 4.456e+00 f 9.366e+03 |g| 5.524e+02 CG   6\n",
      "cg reaches trust region boundary\n",
      "iter  8 act 1.295e+02 pre 1.302e+02 delta 4.729e+00 f 9.104e+03 |g| 2.846e+02 CG   7\n",
      "iter  9 act 6.106e+01 pre 6.041e+01 delta 4.770e+00 f 8.975e+03 |g| 1.543e+02 CG  17\n",
      "iter 10 act 2.232e+00 pre 2.219e+00 delta 4.770e+00 f 8.914e+03 |g| 6.362e+01 CG  12\n",
      "iter 11 act 6.283e-01 pre 6.288e-01 delta 4.770e+00 f 8.912e+03 |g| 6.738e+00 CG  21\n",
      "iter  1 act 2.446e+04 pre 2.446e+04 delta 6.935e-01 f 4.120e+04 |g| 7.055e+04 CG   1\n",
      "cg reaches trust region boundary\n",
      "iter  2 act 3.470e+03 pre 3.470e+03 delta 2.001e+00 f 1.673e+04 |g| 6.052e+03 CG   1\n",
      "cg reaches trust region boundary\n",
      "iter  3 act 5.655e+03 pre 5.149e+03 delta 2.531e+00 f 1.326e+04 |g| 7.254e+03 CG   2\n",
      "cg reaches trust region boundary\n",
      "iter  4 act 2.448e+03 pre 2.109e+03 delta 3.191e+00 f 7.609e+03 |g| 4.424e+03 CG   3\n",
      "iter  5 act 9.381e+02 pre 7.539e+02 delta 3.760e+00 f 5.161e+03 |g| 2.074e+03 CG   4\n",
      "iter  6 act 4.002e+02 pre 3.232e+02 delta 3.956e+00 f 4.223e+03 |g| 1.262e+03 CG   4\n",
      "cg reaches trust region boundary\n",
      "iter  7 act 1.931e+02 pre 1.701e+02 delta 4.605e+00 f 3.823e+03 |g| 5.847e+02 CG   5\n",
      "cg reaches trust region boundary\n",
      "iter  8 act 1.018e+02 pre 9.629e+01 delta 4.899e+00 f 3.630e+03 |g| 3.018e+02 CG   6\n",
      "iter  9 act 4.675e+01 pre 4.446e+01 delta 4.899e+00 f 3.528e+03 |g| 1.631e+02 CG  11\n",
      "iter 10 act 4.386e+00 pre 4.296e+00 delta 4.899e+00 f 3.481e+03 |g| 7.156e+01 CG  10\n",
      "iter 11 act 1.533e+00 pre 1.536e+00 delta 4.899e+00 f 3.477e+03 |g| 1.016e+01 CG  18\n",
      "iter 12 act 1.716e-02 pre 1.715e-02 delta 4.899e+00 f 3.476e+03 |g| 2.194e+00 CG  15\n",
      "iter  1 act 2.062e+04 pre 2.062e+04 delta 6.688e-01 f 3.724e+04 |g| 6.167e+04 CG   1\n",
      "cg reaches trust region boundary\n",
      "iter  2 act 1.869e+03 pre 1.869e+03 delta 2.039e+00 f 1.662e+04 |g| 3.342e+03 CG   1\n",
      "cg reaches trust region boundary\n",
      "iter  3 act 3.219e+03 pre 2.892e+03 delta 2.700e+00 f 1.475e+04 |g| 4.059e+03 CG   2\n",
      "cg reaches trust region boundary\n",
      "iter  4 act 1.911e+03 pre 1.687e+03 delta 3.412e+00 f 1.153e+04 |g| 2.856e+03 CG   3\n",
      "cg reaches trust region boundary\n",
      "iter  5 act 9.455e+02 pre 8.194e+02 delta 4.229e+00 f 9.624e+03 |g| 2.210e+03 CG   3\n",
      "cg reaches trust region boundary\n",
      "iter  6 act 4.906e+02 pre 4.583e+02 delta 4.922e+00 f 8.678e+03 |g| 1.297e+03 CG   4\n",
      "cg reaches trust region boundary\n",
      "iter  7 act 2.620e+02 pre 2.465e+02 delta 5.405e+00 f 8.188e+03 |g| 5.636e+02 CG   6\n",
      "cg reaches trust region boundary\n",
      "iter  8 act 1.208e+02 pre 1.166e+02 delta 5.642e+00 f 7.926e+03 |g| 3.580e+02 CG  11\n",
      "iter  9 act 2.368e+01 pre 2.350e+01 delta 5.642e+00 f 7.805e+03 |g| 1.417e+02 CG  15\n",
      "iter 10 act 1.322e+00 pre 1.319e+00 delta 5.642e+00 f 7.781e+03 |g| 3.216e+01 CG  13\n",
      "iter 11 act 2.640e-01 pre 2.642e-01 delta 5.642e+00 f 7.780e+03 |g| 3.652e+00 CG  24\n",
      "iter  1 act 3.577e+04 pre 3.518e+04 delta 3.046e+00 f 4.092e+04 |g| 6.976e+04 CG   2\n",
      "iter  2 act 1.816e+03 pre 1.563e+03 delta 3.046e+00 f 5.153e+03 |g| 5.142e+03 CG   3\n",
      "iter  3 act 6.636e+02 pre 5.312e+02 delta 3.101e+00 f 3.337e+03 |g| 2.239e+03 CG   4\n",
      "iter  4 act 3.121e+02 pre 2.510e+02 delta 3.698e+00 f 2.673e+03 |g| 1.056e+03 CG   4\n",
      "cg reaches trust region boundary\n",
      "iter  5 act 1.700e+02 pre 1.432e+02 delta 4.634e+00 f 2.361e+03 |g| 4.883e+02 CG   5\n",
      "cg reaches trust region boundary\n",
      "iter  6 act 9.302e+01 pre 8.584e+01 delta 5.287e+00 f 2.191e+03 |g| 2.596e+02 CG   6\n",
      "iter  7 act 3.029e+01 pre 2.894e+01 delta 5.287e+00 f 2.098e+03 |g| 1.429e+02 CG  10\n",
      "iter  8 act 3.723e+00 pre 3.659e+00 delta 5.287e+00 f 2.068e+03 |g| 4.748e+01 CG  12\n",
      "iter  9 act 3.729e-01 pre 3.720e-01 delta 5.287e+00 f 2.064e+03 |g| 7.267e+00 CG  15\n",
      "iter 10 act 9.882e-03 pre 9.884e-03 delta 5.287e+00 f 2.064e+03 |g| 9.323e-01 CG  18\n",
      "iter  1 act 2.422e+04 pre 2.422e+04 delta 6.951e-01 f 4.067e+04 |g| 6.969e+04 CG   1\n",
      "cg reaches trust region boundary\n",
      "iter  2 act 3.170e+03 pre 3.170e+03 delta 2.357e+00 f 1.645e+04 |g| 5.349e+03 CG   1\n",
      "cg reaches trust region boundary\n",
      "iter  3 act 6.157e+03 pre 5.643e+03 delta 2.996e+00 f 1.328e+04 |g| 6.555e+03 CG   2\n",
      "cg reaches trust region boundary\n",
      "iter  4 act 2.486e+03 pre 2.135e+03 delta 3.712e+00 f 7.125e+03 |g| 4.522e+03 CG   4\n",
      "iter  5 act 7.979e+02 pre 6.357e+02 delta 3.712e+00 f 4.639e+03 |g| 2.392e+03 CG   4\n",
      "cg reaches trust region boundary\n",
      "iter  6 act 4.158e+02 pre 3.408e+02 delta 4.946e+00 f 3.841e+03 |g| 9.636e+02 CG   5\n",
      "iter  7 act 1.902e+02 pre 1.626e+02 delta 5.605e+00 f 3.425e+03 |g| 5.324e+02 CG   5\n",
      "iter  8 act 7.380e+01 pre 7.069e+01 delta 5.605e+00 f 3.235e+03 |g| 2.693e+02 CG   8\n",
      "iter  9 act 1.637e+01 pre 1.601e+01 delta 5.605e+00 f 3.161e+03 |g| 1.027e+02 CG  12\n",
      "iter 10 act 2.062e+00 pre 2.043e+00 delta 5.605e+00 f 3.145e+03 |g| 2.498e+01 CG  17\n",
      "iter 11 act 7.041e-02 pre 7.038e-02 delta 5.605e+00 f 3.143e+03 |g| 3.951e+00 CG  16\n",
      "==> Treinando... OK\n",
      "==> Classificando no teste: 9,528 tickets\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8219f86fbffb47fba1d7fc5361979439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas (Embeddings + LinearSVC)\n",
      "  accuracy:    0.7819\n",
      "  f1_macro:    0.7826\n",
      "  f1_weighted: 0.7819\n"
     ]
    }
   ],
   "source": [
    "embedding_classifier = EmbeddingClassifier.linear_svc(\n",
    "    random_state=RANDOM_STATE, verbose=SKLEARN_VERBOSE\n",
    ")\n",
    "embedding_metrics, embedding_pred = evaluate_classifier(embedding_classifier)\n",
    "print_metrics(embedding_metrics, embedding_classifier.name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd893254",
   "metadata": {},
   "source": [
    "Nesta comparação, **embeddings + LinearSVC não ajudou**: o desempenho caiu em relação ao melhor modelo TF-IDF.\n",
    "\n",
    "- **TF-IDF + LinearSVC:** F1 macro = **0.8641**\n",
    "- **Embeddings + LinearSVC:** F1 macro = **0.7826**\n",
    "\n",
    "Uma leitura plausível é que, para este dataset, a **sinalização lexical** (termos e padrões locais) é muito forte para separar classes, e o TF-IDF (word+char n-grams) explora isso diretamente. Já embeddings comprimem a informação em um vetor denso e podem perder parte desses sinais específicos (especialmente se o modelo de embeddings não estiver ajustado ao domínio de tickets).\n",
    "\n",
    "Com isso, seguimos com **TF-IDF + LinearSVC** como nossa melhor opção de classificador linear supervisionado e, em seguida, avaliamos abordagens baseadas em similaridade (RAG) como referência.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16801442",
   "metadata": {},
   "source": [
    "### RAG (k=5): recuperação + classificação\n",
    "\n",
    "Aqui usamos **RAG apenas como mecanismo de retrieval** (sem LLM): dado um ticket, recuperamos os **K tickets mais similares** do conjunto de treino usando embeddings e similaridade de cosseno.\n",
    "\n",
    "Em seguida, transformamos esse retrieval em um classificador de duas formas:\n",
    "- **kNN:** vota pela classe mais frequente entre os K vizinhos.\n",
    "- **voto ponderado:** soma as similaridades por classe e escolhe a maior soma.\n",
    "\n",
    "Essas abordagens servem como referência por serem simples, interpretáveis e diretamente ligadas à ideia de “tickets similares”.\n",
    "\n",
    "#### 3.8.1 Classificação com kNN (k=5)\n",
    "\n",
    "Neste método, cada ticket do teste é rotulado pela maioria entre os 5 vizinhos mais similares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23fa6ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> RAG + kNN (k=5)\n",
      "==> Treinando...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eb1a0d1dcff4de3b9680d6871d7fecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1191 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Treinando... OK\n",
      "==> Classificando no teste: 9,528 tickets\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4488c18a839416f8e238028861f17ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predizendo:   0%|          | 0/9528 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas (RAG + kNN (k=5))\n",
      "  accuracy:    0.8269\n",
      "  f1_macro:    0.8290\n",
      "  f1_weighted: 0.8267\n"
     ]
    }
   ],
   "source": [
    "rag_knn = RagKnnClassifier(k_similar=5)\n",
    "rag_knn_metrics, rag_knn_pred = evaluate_classifier(rag_knn)\n",
    "print_metrics(rag_knn_metrics, rag_knn.name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfaa9c4",
   "metadata": {},
   "source": [
    "#### Classificação com voto ponderado (k=5)\n",
    "\n",
    "Nesta variação, ao invés de contar votos, somamos os scores de similaridade por classe (um vizinho mais próximo contribui mais)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d14e00ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> RAG + Weighted Vote (k=5)\n",
      "==> Treinando...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e762960753884bc2ac7de48b6d6368c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1191 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Treinando... OK\n",
      "==> Classificando no teste: 9,528 tickets\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37c828b4e54d42fb8a962f54245c095f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predizendo:   0%|          | 0/9528 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas (RAG + Weighted Vote (k=5))\n",
      "  accuracy:    0.8269\n",
      "  f1_macro:    0.8290\n",
      "  f1_weighted: 0.8267\n"
     ]
    }
   ],
   "source": [
    "rag_weighted = RagWeightedVoteClassifier(k_similar=5)\n",
    "rag_weighted_metrics, rag_weighted_pred = evaluate_classifier(rag_weighted)\n",
    "print_metrics(rag_weighted_metrics, rag_weighted.name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75212bc5",
   "metadata": {},
   "source": [
    "Nos experimentos acima, os dois classificadores baseados em retrieval (**RAG + kNN** e **RAG + voto ponderado**) tiveram desempenho praticamente idêntico no teste (**F1 macro = 0.8290**, **accuracy = 0.8269**).\n",
    "\n",
    "Como critério de desempate, faz sentido preferir o **voto ponderado**, pois ele leva em conta a intensidade da similaridade (um vizinho muito próximo contribui mais do que um vizinho distante). Mesmo quando as métricas ficam empatadas, essa regra tende a ser mais estável em casos de fronteira.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8bbcdd",
   "metadata": {},
   "source": [
    "### Comparação geral e escolha\n",
    "\n",
    "Consolidamos os resultados para escolher o melhor método para seguir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e604e88",
   "metadata": {},
   "source": [
    "Com a comparação geral, o método eleito para seguir como classificador é o **TF-IDF + LinearSVC** (melhor **F1 macro = 0.8641** no teste).\n",
    "\n",
    "Resumo do que observamos nesta rodada:\n",
    "- **TF-IDF + LinearSVC:** F1 macro = **0.8641**\n",
    "- **RAG (k=5)** (kNN e voto ponderado): F1 macro = **0.8290**\n",
    "- **Embeddings + LinearSVC:** F1 macro = **0.7826**\n",
    "\n",
    "Assim, para as próximas fases, seguimos com **TF-IDF + LinearSVC** como classificador supervisionado principal. O RAG continua valioso como mecanismo de **recuperação de tickets similares** para dar contexto (especialmente na etapa de justificativas com LLM).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ticket-classifier (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
